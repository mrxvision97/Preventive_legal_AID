{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "gpuType": "T4",
      "provenance": []
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers\n",
        "!pip install opencv-python"
      ],
      "metadata": {
        "id": "fKc6ytxDfwBe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "34f1c3af-3e04-444b-cbae-eedd6316db09"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2de3c8d6"
      },
      "source": [
        "# Task\n",
        "Perform real-time human/non-human detection from an HPW100 camera feed using the `Human-vs-NonHuman-Detection` model and continuously print the detection results."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load libraries\n",
        "from huggingface_hub import hf_hub_download\n",
        "from ultralytics import YOLO\n",
        "from supervision import Detections\n",
        "from PIL import Image\n",
        "\n",
        "# download model\n",
        "model_path = hf_hub_download(repo_id=\"arnabdhar/YOLOv8-Face-Detection\", filename=\"model.pt\")\n",
        "\n",
        "# load model\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# inference\n",
        "image_path = \"/content/WhatsApp Image 2024-12-04 at 16.34.57_8aaccd3f.jpg\"\n",
        "output = model(Image.open(image_path))\n",
        "results = Detections.from_ultralytics(output[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hX7KmeAqzqx",
        "outputId": "75b854a1-c0fe-453b-b7d7-b5306747d3f4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x608 1 FACE, 13.3ms\n",
            "Speed: 5.6ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 608)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supervision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQBhHwc0qcxa",
        "outputId": "b7875b1a-8663-40fd-aa51-e1161e2aa336"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting supervision\n",
            "  Downloading supervision-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.12/dist-packages (from supervision) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from supervision) (1.16.3)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from supervision) (3.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from supervision) (6.0.3)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.12/dist-packages (from supervision) (11.3.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from supervision) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.12/dist-packages (from supervision) (4.67.1)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.12/dist-packages (from supervision) (4.12.0.88)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (2025.10.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.17.0)\n",
            "Downloading supervision-0.27.0-py3-none-any.whl (212 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.4/212.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: supervision\n",
            "Successfully installed supervision-0.27.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "9970c02f",
        "outputId": "c8a3f7f5-1524-4289-e572-2b4d574f28ee"
      },
      "source": [
        "import time\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import io\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# 2. Define a JavaScript function for webcam control within a Python function\n",
        "def video_stream_js():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var img;\n",
        "    var dataURL;\n",
        "\n",
        "    async function startCamera() {\n",
        "      div = document.createElement('div');\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      div.appendChild(video);\n",
        "\n",
        "      try {\n",
        "        stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "        video.srcObject = stream;\n",
        "        await video.play();\n",
        "\n",
        "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "        captureCanvas = document.createElement('canvas');\n",
        "        captureCanvas.width = video.videoWidth;\n",
        "        captureCanvas.height = video.videoHeight;\n",
        "        img = document.createElement('img');\n",
        "        img.src = '';\n",
        "        div.appendChild(img);\n",
        "        return true; // Indicate success\n",
        "      } catch (error) {\n",
        "        console.error('Failed to start camera:', error);\n",
        "        if (div) {\n",
        "          document.body.removeChild(div);\n",
        "          div = null;\n",
        "        }\n",
        "        throw error; // Re-throw to ensure Python receives the error type\n",
        "      }\n",
        "    }\n",
        "\n",
        "    async function captureFrame() {\n",
        "      if (!div) {\n",
        "        console.error('Camera not started. Call startCamera() first.');\n",
        "        return '';\n",
        "      }\n",
        "      captureCanvas.getContext('2d').drawImage(video, 0, 0, video.videoWidth, video.videoHeight);\n",
        "      dataURL = captureCanvas.toDataURL('image/jpeg');\n",
        "      img.src = dataURL;\n",
        "\n",
        "      return dataURL;\n",
        "    }\n",
        "\n",
        "    function stopCamera() {\n",
        "      if (stream) {\n",
        "        stream.getTracks().forEach(track => track.stop());\n",
        "      }\n",
        "      if (div) {\n",
        "        document.body.removeChild(div);\n",
        "        div = null;\n",
        "      }\n",
        "    }\n",
        "\n",
        "    google.colab.output.expose(startCamera);\n",
        "    google.colab.output.expose(captureFrame);\n",
        "    google.colab.output.expose(stopCamera);\n",
        "  ''')\n",
        "  display(js)\n",
        "\n",
        "# 3. Create a Python function `video_stream()`\n",
        "def video_stream():\n",
        "  print(\"\\n*** IMPORTANT: Please grant camera access in your browser pop-up to proceed. ***\\n\")\n",
        "  # Use eval_js with an IIAFE to ensure the async startCamera completes and waits for it.\n",
        "  eval_js('(async () => { await startCamera(); })();')\n",
        "\n",
        "# 4. Create another Python function `take_photo()`\n",
        "def take_photo(quality=0.8):\n",
        "  # Call the JavaScript captureFrame function\n",
        "  data = eval_js('captureFrame();')\n",
        "  # Decode the base64 string\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  # Convert to PIL Image\n",
        "  image_pil = Image.open(io.BytesIO(binary))\n",
        "  # Convert to OpenCV format (numpy array)\n",
        "  image_cv = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)\n",
        "  return image_cv\n",
        "\n",
        "# 5. Create a Python function to stop the video stream\n",
        "def stop_video_stream():\n",
        "  display(Javascript('stopCamera();'))\n",
        "\n",
        "# 6. Call the `video_stream_js()` function to expose the JavaScript camera control functions\n",
        "print(\"Initializing webcam functions...\")\n",
        "video_stream_js()\n",
        "\n",
        "# 7. Call the `video_stream()` function to initialize and start the webcam feed\n",
        "video_stream()\n",
        "time.sleep(2) # Added a small delay to ensure JS functions are exposed and camera started\n",
        "print(\"Webcam initialized. Waiting for user input...\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing webcam functions...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var img;\n",
              "    var dataURL;\n",
              "\n",
              "    async function startCamera() {\n",
              "      div = document.createElement('div');\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      div.appendChild(video);\n",
              "\n",
              "      try {\n",
              "        stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "        captureCanvas = document.createElement('canvas');\n",
              "        captureCanvas.width = video.videoWidth;\n",
              "        captureCanvas.height = video.videoHeight;\n",
              "        img = document.createElement('img');\n",
              "        img.src = '';\n",
              "        div.appendChild(img);\n",
              "        return true; // Indicate success\n",
              "      } catch (error) {\n",
              "        console.error('Failed to start camera:', error);\n",
              "        if (div) {\n",
              "          document.body.removeChild(div);\n",
              "          div = null;\n",
              "        }\n",
              "        throw error; // Re-throw to ensure Python receives the error type\n",
              "      }\n",
              "    }\n",
              "\n",
              "    async function captureFrame() {\n",
              "      if (!div) {\n",
              "        console.error('Camera not started. Call startCamera() first.');\n",
              "        return '';\n",
              "      }\n",
              "      captureCanvas.getContext('2d').drawImage(video, 0, 0, video.videoWidth, video.videoHeight);\n",
              "      dataURL = captureCanvas.toDataURL('image/jpeg');\n",
              "      img.src = dataURL;\n",
              "\n",
              "      return dataURL;\n",
              "    }\n",
              "\n",
              "    function stopCamera() {\n",
              "      if (stream) {\n",
              "        stream.getTracks().forEach(track => track.stop());\n",
              "      }\n",
              "      if (div) {\n",
              "        document.body.removeChild(div);\n",
              "        div = null;\n",
              "      }\n",
              "    }\n",
              "\n",
              "    google.colab.output.expose(startCamera);\n",
              "    google.colab.output.expose(captureFrame);\n",
              "    google.colab.output.expose(stopCamera);\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*** IMPORTANT: Please grant camera access in your browser pop-up to proceed. ***\n",
            "\n",
            "Webcam initialized. Waiting for user input...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================\n",
        "# CELL 1: Import Libraries\n",
        "# ====================================\n",
        "import time\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "from supervision import Detections\n",
        "from IPython.display import Javascript, display\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import io\n",
        "import numpy as np\n",
        "\n",
        "# ====================================\n",
        "# CELL 2: Load YOLO Model\n",
        "# ====================================\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "print(\"Loading model...\")\n",
        "model_path = hf_hub_download(repo_id=\"arnabdhar/YOLOv8-Face-Detection\", filename=\"model.pt\")\n",
        "model = YOLO(model_path)\n",
        "print(\"✓ Model loaded!\")\n",
        "\n",
        "# ====================================\n",
        "# CELL 3: Setup Webcam Functions\n",
        "# ====================================\n",
        "def video_stream_js():\n",
        "    js = Javascript('''\n",
        "        var video;\n",
        "        var div = null;\n",
        "        var stream;\n",
        "        var captureCanvas;\n",
        "\n",
        "        async function startCamera() {\n",
        "            div = document.createElement('div');\n",
        "            document.body.appendChild(div);\n",
        "\n",
        "            video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            div.appendChild(video);\n",
        "\n",
        "            try {\n",
        "                stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "                video.srcObject = stream;\n",
        "                await video.play();\n",
        "\n",
        "                google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "                captureCanvas = document.createElement('canvas');\n",
        "                captureCanvas.width = video.videoWidth;\n",
        "                captureCanvas.height = video.videoHeight;\n",
        "                return true;\n",
        "            } catch (error) {\n",
        "                console.error('Failed to start camera:', error);\n",
        "                if (div) {\n",
        "                    document.body.removeChild(div);\n",
        "                    div = null;\n",
        "                }\n",
        "                throw error;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        async function captureFrame() {\n",
        "            if (!div || !video) {\n",
        "                console.error('Camera not started. Call startCamera() first.');\n",
        "                return '';\n",
        "            }\n",
        "            var context = captureCanvas.getContext('2d');\n",
        "            context.drawImage(video, 0, 0, video.videoWidth, video.videoHeight);\n",
        "            return captureCanvas.toDataURL('image/jpeg');\n",
        "        }\n",
        "\n",
        "        function stopCamera() {\n",
        "            if (stream) {\n",
        "                stream.getTracks().forEach(track => track.stop());\n",
        "            }\n",
        "            if (div) {\n",
        "                document.body.removeChild(div);\n",
        "                div = null;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        window.startCamera = startCamera;\n",
        "        window.captureFrame = captureFrame;\n",
        "        window.stopCamera = stopCamera;\n",
        "    ''')\n",
        "    display(js)\n",
        "\n",
        "def video_stream():\n",
        "    print(\"Grant camera access in browser popup\")\n",
        "    return eval_js('startCamera()')\n",
        "\n",
        "def take_photo():\n",
        "    data = eval_js('captureFrame()')\n",
        "    if data is None or data == '':\n",
        "        raise Exception(\"Failed to capture frame. Camera may not be ready.\")\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    image_pil = Image.open(io.BytesIO(binary))\n",
        "    image_cv = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)\n",
        "    return image_cv\n",
        "\n",
        "def stop_video_stream():\n",
        "    display(Javascript('stopCamera();'))\n",
        "\n",
        "print(\"✓ Functions ready!\")\n",
        "\n",
        "# ====================================\n",
        "# CELL 4: Initialize Camera (RUN THIS ONCE)\n",
        "# ====================================\n",
        "print(\"Starting camera...\")\n",
        "video_stream_js()\n",
        "time.sleep(2)  # Wait for JS to load\n",
        "video_stream()\n",
        "time.sleep(4)  # Increased wait time for camera\n",
        "print(\"✓ Camera ready!\")\n",
        "\n",
        "# ====================================\n",
        "# CELL 5: Run Face Detection\n",
        "# ====================================\n",
        "print(\"Starting detection... Press STOP to end\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "frame_count = 0\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        frame_count += 1\n",
        "\n",
        "        print(f\"\\n[Frame #{frame_count}] Time: {time.strftime('%H:%M:%S')}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        try:\n",
        "            # Capture and process\n",
        "            frame_cv = take_photo()\n",
        "            frame_rgb = cv2.cvtColor(frame_cv, cv2.COLOR_BGR2RGB)\n",
        "            image_pil = Image.fromarray(frame_rgb)\n",
        "\n",
        "            # Detect faces\n",
        "            results = model(image_pil)\n",
        "            detections = Detections.from_ultralytics(results[0])\n",
        "            face_detections = detections[detections.class_id == 0]\n",
        "\n",
        "            # Show results\n",
        "            if len(face_detections) > 0:\n",
        "                print(f\"✅ {len(face_detections)} Face(s) Detected\")\n",
        "                for i in range(len(face_detections)):\n",
        "                    conf = face_detections.confidence[i]\n",
        "                    print(f\"   Face {i+1}: Confidence {conf:.2%}\")\n",
        "            else:\n",
        "                print(\"❌ No face detected\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error: {e}\")\n",
        "            print(\"Retrying in 2 seconds...\")\n",
        "            time.sleep(2)\n",
        "            continue\n",
        "\n",
        "        # Wait 1 second before next capture\n",
        "        time.sleep(3)\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"Detection stopped!\")\n",
        "finally:\n",
        "    stop_video_stream()\n",
        "    print(f\"Camera closed. Total frames: {frame_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JH8BMR9ayMy2",
        "outputId": "af7488e2-28f6-4e91-baff-d473ae15bb1e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n",
            "✓ Model loaded!\n",
            "✓ Functions ready!\n",
            "Starting camera...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        var video;\n",
              "        var div = null;\n",
              "        var stream;\n",
              "        var captureCanvas;\n",
              "\n",
              "        async function startCamera() {\n",
              "            div = document.createElement('div');\n",
              "            document.body.appendChild(div);\n",
              "\n",
              "            video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            div.appendChild(video);\n",
              "\n",
              "            try {\n",
              "                stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "\n",
              "                google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "                captureCanvas = document.createElement('canvas');\n",
              "                captureCanvas.width = video.videoWidth;\n",
              "                captureCanvas.height = video.videoHeight;\n",
              "                return true;\n",
              "            } catch (error) {\n",
              "                console.error('Failed to start camera:', error);\n",
              "                if (div) {\n",
              "                    document.body.removeChild(div);\n",
              "                    div = null;\n",
              "                }\n",
              "                throw error;\n",
              "            }\n",
              "        }\n",
              "\n",
              "        async function captureFrame() {\n",
              "            if (!div || !video) {\n",
              "                console.error('Camera not started. Call startCamera() first.');\n",
              "                return '';\n",
              "            }\n",
              "            var context = captureCanvas.getContext('2d');\n",
              "            context.drawImage(video, 0, 0, video.videoWidth, video.videoHeight);\n",
              "            return captureCanvas.toDataURL('image/jpeg');\n",
              "        }\n",
              "\n",
              "        function stopCamera() {\n",
              "            if (stream) {\n",
              "                stream.getTracks().forEach(track => track.stop());\n",
              "            }\n",
              "            if (div) {\n",
              "                document.body.removeChild(div);\n",
              "                div = null;\n",
              "            }\n",
              "        }\n",
              "\n",
              "        window.startCamera = startCamera;\n",
              "        window.captureFrame = captureFrame;\n",
              "        window.stopCamera = stopCamera;\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grant camera access in browser popup\n",
            "✓ Camera ready!\n",
            "Starting detection... Press STOP to end\n",
            "==================================================\n",
            "\n",
            "[Frame #1] Time: 07:24:58\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 (no detections), 9.6ms\n",
            "Speed: 1.6ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "❌ No face detected\n",
            "\n",
            "[Frame #2] Time: 07:25:02\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 1 FACE, 7.0ms\n",
            "Speed: 1.3ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "✅ 1 Face(s) Detected\n",
            "   Face 1: Confidence 50.13%\n",
            "\n",
            "[Frame #3] Time: 07:25:05\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 (no detections), 6.9ms\n",
            "Speed: 1.3ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "❌ No face detected\n",
            "\n",
            "[Frame #4] Time: 07:25:08\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 (no detections), 7.7ms\n",
            "Speed: 1.3ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "❌ No face detected\n",
            "\n",
            "[Frame #5] Time: 07:25:12\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 (no detections), 7.3ms\n",
            "Speed: 1.4ms preprocess, 7.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "❌ No face detected\n",
            "\n",
            "[Frame #6] Time: 07:25:15\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 (no detections), 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "❌ No face detected\n",
            "\n",
            "[Frame #7] Time: 07:25:19\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 (no detections), 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "❌ No face detected\n",
            "\n",
            "[Frame #8] Time: 07:25:22\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 (no detections), 7.7ms\n",
            "Speed: 1.7ms preprocess, 7.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "❌ No face detected\n",
            "\n",
            "[Frame #9] Time: 07:25:25\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 (no detections), 7.6ms\n",
            "Speed: 1.4ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "❌ No face detected\n",
            "\n",
            "[Frame #10] Time: 07:25:29\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 2 FACEs, 9.3ms\n",
            "Speed: 1.5ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "✅ 2 Face(s) Detected\n",
            "   Face 1: Confidence 39.21%\n",
            "   Face 2: Confidence 32.74%\n",
            "\n",
            "[Frame #11] Time: 07:25:32\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 1 FACE, 6.1ms\n",
            "Speed: 1.2ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "✅ 1 Face(s) Detected\n",
            "   Face 1: Confidence 76.25%\n",
            "\n",
            "[Frame #12] Time: 07:25:35\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 2 FACEs, 7.4ms\n",
            "Speed: 1.3ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "✅ 2 Face(s) Detected\n",
            "   Face 1: Confidence 45.69%\n",
            "   Face 2: Confidence 28.61%\n",
            "\n",
            "[Frame #13] Time: 07:25:39\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 2 FACEs, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "✅ 2 Face(s) Detected\n",
            "   Face 1: Confidence 45.39%\n",
            "   Face 2: Confidence 44.78%\n",
            "\n",
            "[Frame #14] Time: 07:25:42\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 1 FACE, 6.9ms\n",
            "Speed: 1.5ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "✅ 1 Face(s) Detected\n",
            "   Face 1: Confidence 68.33%\n",
            "\n",
            "[Frame #15] Time: 07:25:45\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 (no detections), 9.0ms\n",
            "Speed: 3.2ms preprocess, 9.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "❌ No face detected\n",
            "\n",
            "[Frame #16] Time: 07:25:49\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 1 FACE, 6.2ms\n",
            "Speed: 1.3ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "✅ 1 Face(s) Detected\n",
            "   Face 1: Confidence 89.77%\n",
            "\n",
            "[Frame #17] Time: 07:25:52\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 1 FACE, 7.1ms\n",
            "Speed: 1.3ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "✅ 1 Face(s) Detected\n",
            "   Face 1: Confidence 68.66%\n",
            "\n",
            "[Frame #18] Time: 07:25:55\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 1 FACE, 6.1ms\n",
            "Speed: 1.2ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "✅ 1 Face(s) Detected\n",
            "   Face 1: Confidence 74.85%\n",
            "\n",
            "[Frame #19] Time: 07:25:59\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 2 FACEs, 51.1ms\n",
            "Speed: 4.5ms preprocess, 51.1ms inference, 9.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "✅ 2 Face(s) Detected\n",
            "   Face 1: Confidence 63.34%\n",
            "   Face 2: Confidence 38.22%\n",
            "\n",
            "[Frame #20] Time: 07:26:03\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 1 FACE, 26.3ms\n",
            "Speed: 3.7ms preprocess, 26.3ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "✅ 1 Face(s) Detected\n",
            "   Face 1: Confidence 30.67%\n",
            "\n",
            "[Frame #21] Time: 07:26:06\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 (no detections), 6.8ms\n",
            "Speed: 1.4ms preprocess, 6.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "❌ No face detected\n",
            "\n",
            "[Frame #22] Time: 07:26:09\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 (no detections), 6.1ms\n",
            "Speed: 1.2ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "❌ No face detected\n",
            "\n",
            "[Frame #23] Time: 07:26:13\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 (no detections), 7.2ms\n",
            "Speed: 1.3ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "❌ No face detected\n",
            "\n",
            "[Frame #24] Time: 07:26:16\n",
            "--------------------------------------------------\n",
            "\n",
            "0: 480x640 (no detections), 7.2ms\n",
            "Speed: 1.4ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "❌ No face detected\n",
            "\n",
            "==================================================\n",
            "Detection stopped!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "stopCamera();"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Camera closed. Total frames: 24\n"
          ]
        }
      ]
    }
  ]
}