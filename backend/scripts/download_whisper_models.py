"""
Pre-download Whisper models for offline use
Optimized for edge devices
"""
import whisper
import sys
from app.core.edge_optimization import is_edge_device, get_optimal_whisper_model

def download_whisper_models():
    """Download Whisper models for offline use"""
    print("üîç Detecting device capabilities...")
    
    is_edge = is_edge_device()
    optimal_model = get_optimal_whisper_model()
    
    print(f"üì± Device Type: {'Edge Device (Jetson Nano)' if is_edge else 'Standard Device'}")
    print(f"üéØ Recommended Whisper Model: {optimal_model}")
    
    models_to_download = [optimal_model]
    
    # For edge devices, also download tiny as backup
    if is_edge and optimal_model != "tiny":
        models_to_download.append("tiny")
    
    print(f"\nüì• Downloading Whisper models: {', '.join(models_to_download)}")
    print("   This may take 5-15 minutes per model...")
    
    for model_size in models_to_download:
        try:
            print(f"\nüì¶ Downloading {model_size}...")
            whisper.load_model(model_size)
            print(f"‚úÖ {model_size} downloaded and cached")
        except Exception as e:
            print(f"‚ùå Failed to download {model_size}: {e}")
            if model_size == optimal_model:
                print("‚ö†Ô∏è Recommended model failed, trying tiny as fallback...")
                try:
                    whisper.load_model("tiny")
                    print("‚úÖ tiny model downloaded as fallback")
                except Exception as fallback_error:
                    print(f"‚ùå Fallback also failed: {fallback_error}")
                    sys.exit(1)
    
    print("\n‚úÖ Whisper models ready for offline use!")
    print(f"üí° System will use '{optimal_model}' model by default")

if __name__ == "__main__":
    download_whisper_models()

